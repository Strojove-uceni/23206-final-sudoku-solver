{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3XZkDj0hc57IPDA0wurJG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Strojove-uceni/23206-final-sudoku-solver/blob/main/DEMO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sudoku solver\n",
        "\n",
        "Authors: Filip Koňařík, Matěj Popďakunik\n",
        "\n",
        "Abstract: In this project, we wrote a program that can solve Sudoku boards. First, we find the Sudoku in the image, then we use a CNN to recognize the individual digits, and finally, we solve it using a backtracking algorithm.\n",
        "\n",
        "Methodology: In the final version of the project, we used a custom Convolutional Neural Network (CNN) to recognize individual digits, as it allowed us to achieve the best results.\n"
      ],
      "metadata": {
        "id": "obZyXz54HOuu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DEMO"
      ],
      "metadata": {
        "id": "BUvjHs-FIH4-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and definitions of functions"
      ],
      "metadata": {
        "id": "GsgXz-KHLdD7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaEZogh2G0My"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import operator\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import albumentations as A\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imsho\n",
        "\n",
        "\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from google.colab.patches import cv2_imshow\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import SGD\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "!pip install torchmetrics --quiet\n",
        "!pip install lightning --quiet\n",
        "import lightning.pytorch as pl\n",
        "from lightning.pytorch.loggers import CSVLogger\n",
        "from torchmetrics import ConfusionMatrix, Accuracy\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sudoku detection"
      ],
      "metadata": {
        "id": "9yEfMNT1L_YI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find four corners of sudoku grid using OpenCV functions\n",
        "def find_corners(sudoku_image):\n",
        "  sudoku_image = cv2.cvtColor(sudoku_image, cv2.COLOR_BGR2GRAY)\n",
        "  cv2.GaussianBlur(sudoku_image, (9, 9), 0, sudoku_image)\n",
        "  cv2.adaptiveThreshold(sudoku_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2, sudoku_image)\n",
        "\n",
        "  contours = cv2.findContours(sudoku_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  contours = contours[0] if len(contours) == 2 else contours[1]\n",
        "  contours = sorted(contours, key=cv2.contourArea, reverse=True) #sort contours to fing the largest one\n",
        "  largest_contour = contours[0]\n",
        "\n",
        "  corners1 = largest_contour[:4].copy()\n",
        "  corners2 = largest_contour[:4].copy()\n",
        "\n",
        "  # Find corners of the sudoku\n",
        "  # We for 2 squares and than check which square has larger area -> works also for rotated images\n",
        "  for pt in largest_contour:\n",
        "    if pt[0][0] + pt[0][1] < corners1[0][0][0] + corners1[0][0][1]: corners1[0] = pt\n",
        "    if pt[0][0] - pt[0][1] > corners1[1][0][0] - corners1[1][0][1]: corners1[1] = pt\n",
        "    if pt[0][0] + pt[0][1] > corners1[2][0][0] + corners1[2][0][1]: corners1[2] = pt\n",
        "    if pt[0][0] - pt[0][1] < corners1[3][0][0] - corners1[3][0][1]: corners1[3] = pt\n",
        "    if pt[0][0] < corners2[0][0][0]: corners2[0] = pt\n",
        "    if pt[0][1] < corners2[1][0][1]: corners2[1] = pt\n",
        "    if pt[0][0] > corners2[2][0][0]: corners2[2] = pt\n",
        "    if pt[0][1] > corners2[3][0][1]: corners2[3] = pt\n",
        "  if cv2.contourArea(corners1) > cv2.contourArea(corners2):\n",
        "    return corners1.squeeze()\n",
        "  else:\n",
        "    return corners2.squeeze()"
      ],
      "metadata": {
        "id": "6L4S4K6QHRQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example"
      ],
      "metadata": {
        "id": "HfdRmhONMPJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#testing\n",
        "image = cv2.imread(\"drive/MyDrive/Sudoku/sudoku_data_aug/63.jpg\")\n",
        "corners = find_corners(image)\n",
        "cv2.drawContours(image, corners, -1, (0,255,0), 15)\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "XYb7HQ7sMRzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Digit classification\n"
      ],
      "metadata": {
        "id": "eZDmAouVNEUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = 10\n",
        "\n",
        "#class representing dataset of images of printed sudoku digits from photos\n",
        "class SudokuNumberDataset(Dataset):\n",
        "  def __init__(self, root_dir, csv_path, output_size, n_images_to_process=4000):\n",
        "    self.sudoku_df = pd.read_csv(csv_path) #dataframe containing info about sudoku photos\n",
        "    self.n_images = n_images_to_process*81 #number of digit images\n",
        "\n",
        "    #create empty tensors to store digit images and labels in\n",
        "    self.X = torch.empty((self.n_images, 1, output_size[0], output_size[1]))\n",
        "    self.y = torch.empty(self.n_images, dtype=torch.long)\n",
        "\n",
        "    #ids of images from the original dataset\n",
        "    #images from data augmentation are stored consecutively so we want to sample across the whole dataset\n",
        "    original_ids = np.linspace(0, 3999, n_images_to_process).astype(int)\n",
        "\n",
        "\n",
        "    for id in range(n_images_to_process):\n",
        "      #load greyscale images and corner keypoints\n",
        "      img_name = os.path.join(root_dir, str(original_ids[id]) + \".jpg\")\n",
        "      image = cv2.cvtColor(cv2.imread(img_name), cv2.COLOR_BGR2GRAY)\n",
        "      keypoints = np.array(self.sudoku_df.loc[original_ids[id]][4:]).reshape((4, 2)).astype(\"float32\")\n",
        "\n",
        "      grid_side = max([np.sqrt(p[0]*p[0] + p[1]*p[1]) for p in keypoints]) #find longes distance between corners\n",
        "\n",
        "      #transform the sudoku image to a square\n",
        "      keypoints_new = np.array([[0, 0], [grid_side - 1, 0], [grid_side - 1, grid_side - 1], [0, grid_side - 1]], dtype='float32')\n",
        "      transform = cv2.getPerspectiveTransform(keypoints, keypoints_new)\n",
        "      image = cv2.warpPerspective(image, transform, (int(grid_side), int(grid_side)))\n",
        "\n",
        "      #cut the square sudoku image into images of individual cells\n",
        "      cell_side = grid_side / 9\n",
        "      for i in range(9):\n",
        "        for j in range(9):\n",
        "          top_left = (int(i * cell_side), int(j * cell_side))\n",
        "          bottom_right = (int((i + 1) * cell_side), int((j + 1) * cell_side))\n",
        "          number_image = image[top_left[0]:bottom_right[0], top_left[1]:bottom_right[1]]\n",
        "          number_image = cv2.resize(number_image, output_size)\n",
        "          self.X[id*81 + i*9 + j] = torch.Tensor(number_image).unsqueeze(0)\n",
        "          self.y[id*81 + i*9 + j] = torch.tensor(int(self.sudoku_df.loc[original_ids[id]][\"nums\"][i*9 + j]))\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.X[index], self.y[index]\n",
        "\n",
        "  def __len__(self):\n",
        "      return self.n_images\n",
        "\n",
        "  #normalize the images\n",
        "  def normalize(self, mean=None, std=None):\n",
        "    if mean == None and std == None:\n",
        "      mean = self.X.mean((0, 2, 3))[:, None, None]\n",
        "      std = self.X.std((0, 2, 3))[:, None, None]\n",
        "      print(\"Mean:\", mean, \"Std:\", std)\n",
        "      self.X = (self.X - mean) / std"
      ],
      "metadata": {
        "id": "rfe9ksN4NJFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#a convolutional neural network to classify digits from sudoku photos\n",
        "class DigitClassifier(pl.LightningModule):\n",
        "  def __init__(self, image_shape, learning_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.loss_fn = nn.CrossEntropyLoss()\n",
        "    self.learning_rate = learning_rate\n",
        "\n",
        "    #convolutional part of the network\n",
        "    self.cnn_layers = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=1, out_channels=12, kernel_size=3),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "        nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "\n",
        "    conv_output_shape = (int(((image_shape[0] - 2) / 2 - 2) / 2),\n",
        "                         int(((image_shape[1] - 2) / 2 - 2) / 2))\n",
        "    #linear part of the network\n",
        "    self.linear_layers = nn.Sequential(\n",
        "        nn.Linear(in_features=conv_output_shape[0]*conv_output_shape[1]*24, out_features=64),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.2),\n",
        "        nn.Linear(in_features=64, out_features=n_classes)\n",
        "        )\n",
        "\n",
        "  def forward(self, x):\n",
        "    y = self.cnn_layers(x)\n",
        "    y = y.view(y.size(0), -1)\n",
        "    y = self.linear_layers(y)\n",
        "    y = F.softmax(y, dim=1)\n",
        "    return y\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    x, y = batch\n",
        "    y_hat = self(x)\n",
        "    loss = self.loss_fn(y_hat, y)\n",
        "    self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    x, y = batch\n",
        "    y_hat = self(x)\n",
        "    val_loss = self.loss_fn(y_hat, y)\n",
        "    accuracy = Accuracy(task=\"multiclass\", num_classes=10).to(\"cuda:0\")\n",
        "    self.log('val_loss', val_loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "    self.log('acc', accuracy(y_hat, y), on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "    return val_loss\n",
        "\n",
        "  def predict_step(self, batch, batch_idx):\n",
        "    x, _ = batch\n",
        "    y_hat = self(x)\n",
        "    return y_hat\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    return SGD(self.parameters(), lr=self.learning_rate)"
      ],
      "metadata": {
        "id": "dIgFcVkkNVx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After training we get the following confusion matrix\n",
        "\n",
        "|       | 0     | 1     | 2     | 3     | 4     | 5     | 6     | 7     | 8     | 9     |\n",
        "|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|\n",
        "| **0** | 10373 | 0     | 0     | 0     | 0     | 1     | 0     | 2     | 0     | 0     |\n",
        "| **1** | 0     | 612   | 0     | 0     | 0     | 0     | 0     | 0     | 0     | 0     |\n",
        "| **2** | 0     | 0     | 683   | 0     | 0     | 0     | 0     | 1     | 0     | 0     |\n",
        "| **3** | 1     | 0     | 0     | 679   | 0     | 0     | 0     | 0     | 0     | 0     |\n",
        "| **4** | 0     | 0     | 0     | 0     | 625   | 0     | 0     | 0     | 0     | 0     |\n",
        "| **5** | 0     | 1     | 0     | 2     | 2     | 629   | 2     | 0     | 0     | 0     |\n",
        "| **6** | 0     | 0     | 0     | 0     | 0     | 0     | 564   | 0     | 0     | 1     |\n",
        "| **7** | 0     | 0     | 0     | 0     | 0     | 0     | 0     | 668   | 0     | 0     |\n",
        "| **8** | 0     | 0     | 0     | 0     | 0     | 0     | 2     | 0     | 738   | 0     |\n",
        "| **9** | 0     | 0     | 0     | 0     | 0     | 0     | 0     | 0     | 0     | 614   |\n",
        "\n",
        "\n",
        "As we can see, the network has a 99% accuracy.\n"
      ],
      "metadata": {
        "id": "0EYT3ZqzNjCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Showcase"
      ],
      "metadata": {
        "id": "qAIsO68OHSJl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v6-gfsceHQEq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}